{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div#notebook {\n",
       " font-family: \"Exo_2\", sans-serif;\n",
       "}\n",
       "\n",
       ".rendered_html h1,\n",
       ".text_cell_render h1 {\n",
       " color: #126dce;\n",
       " font-size: 220%;\n",
       " text-align: center;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h2,\n",
       ".text_cell_render h2 {\n",
       " text-align: center;\n",
       " font-size: 170%;\n",
       " color: #126dce;\n",
       " font-style: normal;\n",
       " font-weight: lighter;\n",
       "}\n",
       ".rendered_html h3,\n",
       ".text_cell_render h3 {\n",
       " font-size: 150%;\n",
       " color: #126dce;\n",
       " font-weight: lighter;\n",
       " text-decoration: italic;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h4,\n",
       ".text_cell_render h4 {\n",
       " font-size: 120%;\n",
       " color: #126dce;\n",
       " font-weight: underline;\n",
       " font-style: normal;\n",
       "}\n",
       ".rendered_html h5,\n",
       ".text_cell_render h5 {\n",
       " font-size: 100%;\n",
       " color: #2f2f2f;\n",
       " font-weight: lighter;\n",
       " text-decoration: underline;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# setup\n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML('<style>.prompt{width: 0px; min-width: 0px; visibility: collapse}</style>'))\n",
    "display(HTML(open('rise.css').read()))\n",
    "\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\", font_scale=1.5, rc={'figure.figsize':(12, 6)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CMPS 2200\n",
    "# Introduction to Algorithms\n",
    "\n",
    "## Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Today's agenda:\n",
    "\n",
    "- Randomized Linear Time Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Given an unsorted list $a$ and an integer $k$ ($0\\leq k< |a|$), the **order statistics** problem asks us to return the $k$th smallest element from $a$. We also refer to the $k$th smallest element the element of *rank* $k$.  \n",
    "\n",
    "Example: Let $a=\\langle 2, 5, 4, 1, 3, -1, 99\\rangle.$ For $k=0$, the \"$0$th smallest\" element is the minimum element in $a$, or $-1$. For $k=n-1$, it is the maximum, or $99$. For $k=3$, we return $3$.\n",
    "\n",
    "Before we come up with a randomized algorithm, we can make a couple of simple observations.\n",
    "\n",
    "First, any algorithm for this problem requires $\\Omega(n)$ work. Why?\n",
    "\n",
    "Second, we can reduce this problem to sorting: we sort $a$ and return the $k$th element of this sorted list. This requires $O(n\\log n)$ time. \n",
    "\n",
    "Can we do any better? Sorting seems like overkill since we don't really need to rearrange all the elements, or even return a list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A useful observation is that the $k$th smallest element in $a$ *partitions* $a$ into a set of $k-1$ smaller elements, and a set of $n-k-1$ larger elements. \n",
    "\n",
    "Example: Suppose $a=\\langle 2, 5, 4, 1, 3, -1, 99\\rangle$ and $k=3$. So $3$ is larger than $\\langle 2, 1, -1 \\rangle$ and smaller than $\\langle5, 4, 99\\rangle$.\n",
    "\n",
    "Notice that *for any* element $x$ in the list, we can look at each element in the list to compute the rank of $x$. This can be done in $O(n)$ work and $O(\\log n)$ span. \n",
    "\n",
    "Example: Suppose $a=\\langle 2, 5, 4, 1, 3, -1, 99\\rangle$ and $k=3$. So $a[0] = 2$ is larger than 2 elements ($\\langle 1, -1 \\rangle$) and smaller than 5 elements ($\\langle 5, 4, 3, 99\\rangle$).\n",
    "\n",
    "We can see from this example that once we've identified 2 smaller elements, the element of rank $k=3$ in $a$ must be in $\\langle5, 4, 3, 99\\rangle$. Moreover it's rank is $k-2 = 1$ in this list. \n",
    "\n",
    "This is a little like binary search, but with the partition step helping establish some order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This observation the following recursive algorithm.\n",
    "\n",
    "<p>\\begin{array}{ll}  \n",
    "\\mathit{simple-select}~a~k =   \n",
    "\\\\  \n",
    "\\texttt{let}  \n",
    "\\\\  \n",
    "~~~~p = a[0]   \n",
    "\\\\  \n",
    "~~~~\\ell = \\left\\langle\\, x \\in a \\;|\\; x < p \\,\\right\\rangle  \n",
    "\\\\  \n",
    "~~~~r = \\left\\langle\\, x \\in a \\;|\\; x > p \\,\\right\\rangle  \n",
    "\\\\  \n",
    "\\texttt{in}  \n",
    "\\\\  \n",
    "~~~~\\texttt{if}~(k < |\\ell|)~\\texttt{then}~\\mathit{select}~\\ell~k  \n",
    "\\\\  \n",
    "~~~~\\texttt{else if}~(k < |a| - |r|)~\\texttt{then}~p  \n",
    "\\\\  \n",
    "~~~~\\texttt{else}~\\mathit{select}~r~(k - (|a| - |r|))  \n",
    "\\\\  \n",
    "\\texttt{end}  \n",
    "\\end{array}</p>\n",
    "\n",
    "We just have one recursive call so no parallelism there. However, we can use filter to partition in parallel. This has $O(|a|)$ work $O(\\log |a|)$ span.\n",
    "\n",
    "What is the total work over all recursions? We know that the work in each recursive call is the $\\max\\{W(\\mid l\\mid, W(\\mid r\\mid\\} + O(n)$. \n",
    "\n",
    "Consider the case where $a$ is a sorted list. Then in every call, $\\ell = \\emptyset$, and $\\mid r\\mid = n-1$. Thus we have $W(n) = W(n-1) + n = O(n^2)$. This is worse than just sorting the list!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The problem is that we just don't know anything about the element we're using for the partition. How do we avoid this worst case?\n",
    "\n",
    "Pick a random element, or **pivot**, for partitioning!\n",
    "\n",
    "<p>\\begin{array}{ll}  \n",
    "\\mathit{select}~a~k =   \n",
    "\\\\  \n",
    "\\texttt{let}  \n",
    "\\\\  \n",
    "~~~~p = \\mbox{pick a uniformly random element from}~a   \n",
    "\\\\  \n",
    "~~~~\\ell = \\left\\langle\\, x \\in a \\;|\\; x < p \\,\\right\\rangle  \n",
    "\\\\  \n",
    "~~~~r = \\left\\langle\\, x \\in a \\;|\\; x > p \\,\\right\\rangle  \n",
    "\\\\  \n",
    "\\texttt{in}  \n",
    "\\\\  \n",
    "~~~~\\texttt{if}~(k < |\\ell|)~\\texttt{then}~\\mathit{select}~\\ell~k  \n",
    "\\\\  \n",
    "~~~~\\texttt{else if}~(k < |a| - |r|)~\\texttt{then}~p  \n",
    "\\\\  \n",
    "~~~~\\texttt{else}~\\mathit{select}~r~(k - (|a| - |r|))  \n",
    "\\\\  \n",
    "\\texttt{end}  \n",
    "\\end{array}</p>\n",
    "\n",
    "Notice that the probability of the worst-case is vanishingly small. \n",
    "\n",
    "The size of the $l$ and $r$ will depend on the random choice. Thus the recurrences describing the work and span depend on each random choice and we need to find their expected asymptotic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's get some intution for what's happening. We saw that the work of our algorithm depends on $\\max\\{W(\\mid l\\mid, W(\\mid r\\mid\\}$ in each recursive call. While there is only a $1/n$ probability of choosing a balanced split, any constant fraction reduction in the size of the larger list yields good performance. \n",
    "\n",
    "So, suppose we knew that $\\max\\{W(\\mid l\\mid, W(\\mid r\\mid\\} \\leq W(3n/4)$. This would be a good enough split since the overall work would be $W(n) = W(3n/4) + n = O(n)$.\n",
    "\n",
    "We can examine where $p$ might land in the sorted version of $a$, to understand the probability of a good split.\n",
    "\n",
    "<img width=\"60%\" src=\"selection-intuition.jpg\"/>\n",
    "\n",
    "We can see that $\\mathbf{P}[\\max\\{W(\\mid l\\mid, W(\\mid r\\mid\\} \\leq W(3n/4)] = 1/2$.\n",
    "\n",
    "If we think of each choice of pivot as a coin flip (\"good\" vs. \"bad\") then the expected number of pivot choices to reduce the input to $3n/4$ is 2. \n",
    "\n",
    "In other words, every two recursions yields the desired reduction in list size, and so in expectation we will do linear work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's analyze the performance more closely. Let $X(n)$ be the fractional size of the larger side of the split, for an input of size $n$. So $X(n) = \\max{|l|, |r|}/n$. Then the work and span recurrences are:\n",
    "\n",
    "$W(n) \\leq W(X(n) \\cdot n) + O(n) $\n",
    "\n",
    "$S(n) \\leq S(X(n) \\cdot n) + O(\\lg n)$ \n",
    "\n",
    "\n",
    "First, we'll bound $\\mathbf{E}[X(n)].$ As we discussed above, if $l = i$, then $r = n - i -1$. Using the fact that the probability of the pivot being any particular $i$ is $1/n$, we have:\n",
    "\n",
    "$\\begin{eqnarray*}\n",
    " \\mathbf{E}\\left[{X(n)}\\right] &=& \\frac{1}{n} \\sum_{i=0}^{n-1} \\frac{\\max\\{i, n-i-1\\}}{n} \\\\\n",
    " &\\leq & \\frac{1}{n} \\sum_{j=n/2}^{n-1} \\frac{2}{n}\\cdot j \\\\\n",
    " &\\leq & \\frac{3}{4}  \n",
    "\\end{eqnarray*}$\n",
    "\n",
    "\n",
    "The second step follows from the fact that $\\sum_{i=x}^y i = \\frac{1}{2}(x+y)(y - x + 1).$ It might seem tempting to say that we are done. However, we could get \"unlucky\" in a series of recursions even though $\\mathbf{E}[X(n)]\\leq 3/4.$ We will show the following.\n",
    "\n",
    "**Theorem.** At the $d^{th}$ level of recursion, the size of the input is $(3/4)^d n$ in expectation.\n",
    "\n",
    "**Proof**: We can prove this by induction. \n",
    "\n",
    "The base case $d=0$ holds trivially. \n",
    "\n",
    "For the inductive step, we make the inductive hypothesis that our theorem holds for $d  \\ge 0$ and will show that it holds after the $d+1^{st}$ recursive call. \n",
    "\n",
    "For the $d^{th}$ recursive call, let $Y_d$ be denote the instance size and let $Z_d$ be the rank of the pivot. For any value of $y$ and $z$, let $f(y,z)$ be the fraction of the input reduced by the choice of the pivot at position $z$ for an input of size $y$. The expected input size in the $(d+1)^{st}$ call is:\n",
    "\n",
    "$\\begin{eqnarray*}  \n",
    "\\mathbf{E}[Y_{d+1}] &=& \\sum_{y,z}{y\\cdot f(y,z) \\mathbf{P}_{Y_d,Z_d}(y,z)}   \\\\  \n",
    "& = & \\sum_{y}{\\sum_{z}{y f(y,z) \\mathbf{P}_{Y_d}(y) \\mathbf{P}_{Z_d \\mid Y_d}(z \\mid y)}}   \n",
    "\\\\  \n",
    "&= &\\sum_{y}{y \\mathbf{P}_{Y_d}(y) \\sum_{z}{f(y,z) \\mathbf{P}_{Z_d \\mid Y_d}(z \\mid y)}}   \\\\  \n",
    "&= & \\sum_{y}{y \\mathbf{P}_{Y_d}(y) \\mathbf{E}\\left[{X(y)}\\right]} \\\\  \n",
    "& \\le & \\frac{3}{4} \\sum_{y}{y \\mathbf{P}_{Y_d}(y)} \\\\ \n",
    "& \\le & \\frac{3}{4} \\mathbf{E}\\left[{Y_d}\\right].  \n",
    "\\end{eqnarray*}$\n",
    "\n",
    "The second step uses the definition of conditional probability, and the third step uses the definition of $\\mathbf{E}[X(y)].$ This proves the theorem since we can repeatedly apply the bound. The theorem then shows that $\\mathbf{E}[W(n)] = O(n)$. \n",
    "\n",
    "For the span we can also use the theorem to show that at each level the span is $O(\\log n)$. [By showing that the number of levels is $O(\\log n)$ with high probability](https://www.diderot.one/courses/43/books/185/part/333/chapter/2686#atom-176204), we can establish that the span is $O(\\log^2 n)$ with high probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "rise": {
   "autolaunch": true,
   "controls": false,
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple",
   "transition": "fade"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
